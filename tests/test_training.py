# tests/test_training.py
# Unit tests for the model training script (src/train_model.py).

import subprocess
import sys
import os
import json
from pathlib import Path
import shutil # For cleaning up test outputs
from typing import Tuple, Optional, Dict # CORRECTED: Added Optional, Dict, Tuple

import pytest # Pytest for test discovery and execution
import onnx # For checking ONNX models

# Determine project root assuming tests/ is one level down from project root
PROJECT_ROOT = Path(__file__).resolve().parent.parent
OUTPUT_MODEL_DIR = PROJECT_ROOT / "models" / "side" # Expected output for side model
OUTPUT_OTHER_DIR_BASE = PROJECT_ROOT / "output" # Base for logs, checkpoints, label_maps
LABEL_MAP_PATH = OUTPUT_OTHER_DIR_BASE / "label_maps" / "side_label_map.json"

# Expected number of classes for the 'side' model
EXPECTED_SIDE_CLASSES = 5
EXPECTED_SIDE_LABEL_MAP = {
    "0": "obverse",
    "1": "memorial",
    "2": "shield",
    "3": "wheat",
    "4": "bicentennial"
}

@pytest.fixture(scope="module") # Run once per module (this file)
def cleanup_test_outputs():
    """Fixture to clean up files generated by tests before and after tests run."""
    # Cleanup before tests
    if OUTPUT_MODEL_DIR.exists():
        shutil.rmtree(OUTPUT_MODEL_DIR)
    if (OUTPUT_OTHER_DIR_BASE / "checkpoints").exists():
        shutil.rmtree(OUTPUT_OTHER_DIR_BASE / "checkpoints")
    if (OUTPUT_OTHER_DIR_BASE / "training_logs").exists():
        shutil.rmtree(OUTPUT_OTHER_DIR_BASE / "training_logs")
    if LABEL_MAP_PATH.exists(): # Check before unlinking
        try:
            LABEL_MAP_PATH.unlink()
        except FileNotFoundError:
            pass # Already gone or never created
    
    yield # This is where the testing happens

    # Cleanup after tests (optional, can be useful to inspect outputs)
    # print("Test outputs cleanup (post-run)...")
    # if OUTPUT_MODEL_DIR.exists():
    #     shutil.rmtree(OUTPUT_MODEL_DIR)
    # if (OUTPUT_OTHER_DIR_BASE / "checkpoints").exists():
    #     shutil.rmtree(OUTPUT_OTHER_DIR_BASE / "checkpoints")
    # if (OUTPUT_OTHER_DIR_BASE / "training_logs").exists():
    #     shutil.rmtree(OUTPUT_OTHER_DIR_BASE / "training_logs")
    # if LABEL_MAP_PATH.exists():
    #     try:
    #         LABEL_MAP_PATH.unlink()
    #     except FileNotFoundError:
    #         pass


def find_onnx_files(directory: Path, model_type: str) -> Tuple[Optional[Path], Optional[Path]]:
    """Finds FP32 and INT8 ONNX files in the directory for a given model type."""
    fp32_file, int8_file = None, None
    if directory.exists():
        for f in directory.iterdir():
            if f.is_file() and f.name.startswith(model_type) and f.name.endswith(".onnx"):
                if "_fp32.onnx" in f.name:
                    fp32_file = f
                elif "_int8.onnx" in f.name:
                    int8_file = f
    return fp32_file, int8_file

def test_train_side_model_one_epoch(cleanup_test_outputs):
    """
    Tests training the 'side' model for one epoch on 'data_examples/',
    verifies ONNX export, and checks model integrity.
    """
    # Command to run the training script
    command = [
        sys.executable, 
        "-m", "src.train_model", 
        "-m", "side",            
        "--epochs", "1",
        "--device", "cpu",
        "--data_examples",       
        "--batch_size", "4",     
    ]

    print(f"Running command: {' '.join(command)}")
    process = subprocess.run(command, cwd=PROJECT_ROOT, capture_output=True, text=True, check=False)

    print("STDOUT:")
    print(process.stdout)
    print("STDERR:")
    print(process.stderr)

    assert process.returncode == 0, f"Training script failed with error: {process.stderr}"

    fp32_onnx_path, int8_onnx_path = find_onnx_files(OUTPUT_MODEL_DIR, "side")

    assert fp32_onnx_path is not None, "FP32 ONNX model file not found."
    assert fp32_onnx_path.exists(), f"FP32 ONNX file {fp32_onnx_path} does not exist."
    
    assert int8_onnx_path is not None, "INT8 ONNX model file not found (check logs for quantization errors)."
    assert int8_onnx_path.exists(), f"INT8 ONNX file {int8_onnx_path} does not exist."

    print(f"Checking FP32 ONNX model: {fp32_onnx_path}")
    onnx_model_fp32 = onnx.load(str(fp32_onnx_path))
    onnx.checker.check_model(onnx_model_fp32)

    output_info_fp32 = [info for info in onnx_model_fp32.graph.output if info.name == "output"]
    assert len(output_info_fp32) == 1, "Could not find 'output' in the FP32 ONNX graph."
    
    output_shape_fp32 = output_info_fp32[0].type.tensor_type.shape
    num_classes_dim_fp32 = None
    if len(output_shape_fp32.dim) == 2:
        num_classes_dim_fp32 = output_shape_fp32.dim[1].dim_value
    assert num_classes_dim_fp32 == EXPECTED_SIDE_CLASSES, \
        f"FP32 ONNX model output shape for classes is {num_classes_dim_fp32}, expected {EXPECTED_SIDE_CLASSES}."

    found_label_map_in_onnx: Dict[str, str] = {} # Ensure type hint for clarity
    for prop in onnx_model_fp32.metadata_props:
        if prop.key.startswith("label_"):
            try:
                label_index_str = prop.key.split("_", 1)[1] # Split only on the first underscore
                # No int conversion needed if keys in EXPECTED_SIDE_LABEL_MAP are already strings
                found_label_map_in_onnx[label_index_str] = prop.value
            except IndexError:
                print(f"Warning: Could not parse label index from ONNX metadata key: {prop.key}")

    assert found_label_map_in_onnx == EXPECTED_SIDE_LABEL_MAP, \
        f"Label map in FP32 ONNX metadata mismatch.\nFound: {found_label_map_in_onnx}\nExpected: {EXPECTED_SIDE_LABEL_MAP}"

    print(f"Checking INT8 ONNX model: {int8_onnx_path}")
    onnx_model_int8 = onnx.load(str(int8_onnx_path))
    onnx.checker.check_model(onnx_model_int8)

    output_info_int8 = [info for info in onnx_model_int8.graph.output if info.name == "output"]
    assert len(output_info_int8) == 1, "Could not find 'output' in the INT8 ONNX graph."
    
    output_shape_int8 = output_info_int8[0].type.tensor_type.shape
    num_classes_dim_int8 = None
    if len(output_shape_int8.dim) == 2:
        num_classes_dim_int8 = output_shape_int8.dim[1].dim_value
    assert num_classes_dim_int8 == EXPECTED_SIDE_CLASSES, \
        f"INT8 ONNX model output shape for classes is {num_classes_dim_int8}, expected {EXPECTED_SIDE_CLASSES}."

    assert LABEL_MAP_PATH.exists(), f"Label map JSON file not found at {LABEL_MAP_PATH}"
    with open(LABEL_MAP_PATH, 'r') as f:
        saved_label_map = json.load(f)
    
    assert saved_label_map == EXPECTED_SIDE_LABEL_MAP, \
        f"Saved label map content mismatch.\nFound: {saved_label_map}\nExpected: {EXPECTED_SIDE_LABEL_MAP}"

    assert "Loaded PennyDataset" in process.stdout, "Dataset loading message not found in stdout."
    assert "Epoch 1/1" in process.stdout, "Epoch progress message not found in stdout."
    assert f"{OUTPUT_MODEL_DIR.name}" in process.stdout, "ONNX export message directory part not found in stdout."

    print("test_train_side_model_one_epoch passed successfully.")
